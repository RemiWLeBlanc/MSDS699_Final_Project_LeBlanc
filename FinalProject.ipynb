{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Remi LeBlanc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Research Question / Hypothesis\n",
    "----\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "My aim is to predict the burned area (area) of forest fires, in the northeast region of Portugal. Based on the the spatial, temporal, and weather variables where the fire is spotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from   sklearn.impute             import *\n",
    "from   sklearn.pipeline           import Pipeline\n",
    "from   sklearn.preprocessing      import *\n",
    "from   sklearn.tree               import DecisionTreeRegressor, ExtraTreeRegressor\n",
    "from   sklearn.model_selection    import train_test_split, RandomizedSearchCV\n",
    "from   sklearn.linear_model       import LinearRegression\n",
    "from   sklearn.metrics            import mean_squared_error\n",
    "from   sklearn.ensemble           import RandomForestRegressor, AdaBoostRegressor, GradientBoostingRegressor\n",
    "from   sklearn.inspection         import permutation_importance\n",
    "from   sklearn.compose            import ColumnTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Load Data\n",
    "-----"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "fires = pd.read_csv('forestFires.csv') #https://www.openml.org/d/42363"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "1. X - x-axis spatial coordinate within the Montesinho park map: 1 to 9\n",
    "\n",
    "2. Y - y-axis spatial coordinate within the Montesinho park map: 2 to 9\n",
    "\n",
    "3. month - month of the year: 'jan' to 'dec'\n",
    "\n",
    "4. day - day of the week: 'mon' to 'sun'\n",
    "\n",
    "5. FFMC - FFMC index from the FWI system: 18.7 to 96.20 https://www.nwcg.gov/publications/pms437/cffdrs/fire-weather-index-system \n",
    "\n",
    "6. DMC - DMC index from the FWI system: 1.1 to 291.3\n",
    "\n",
    "7. DC - DC index from the FWI system: 7.9 to 860.6\n",
    "\n",
    "8. ISI - ISI index from the FWI system: 0.0 to 56.10\n",
    "\n",
    "9. temp - temperature in Celsius degrees: 2.2 to 33.30\n",
    "\n",
    "10. RH - relative humidity in %: 15.0 to 100\n",
    "\n",
    "11. wind - wind speed in km/h: 0.40 to 9.40\n",
    "\n",
    "12. rain - outside rain in mm/m2 : 0.0 to 6.4\n",
    "\n",
    "13. area - the burned area of the forest (in ha): 0.00 to 1090.84"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([508.,   6.,   1.,   0.,   0.,   0.,   1.,   0.,   0.,   1.]),\n",
       " array([   0.   ,  109.084,  218.168,  327.252,  436.336,  545.42 ,\n",
       "         654.504,  763.588,  872.672,  981.756, 1090.84 ]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(fires['area'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The data is clearly has some outliers. However, is this case these outliers are very important to attempt to predict (big fire)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "X        0\n",
       "Y        0\n",
       "month    0\n",
       "day      0\n",
       "FFMC     0\n",
       "DMC      0\n",
       "DC       0\n",
       "ISI      0\n",
       "temp     0\n",
       "RH       0\n",
       "wind     0\n",
       "rain     0\n",
       "area     0\n",
       "dtype: int64"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fires.isna().sum() # There are no NA values in the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Line"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Compute a baseline with a simple Linear Regressor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = fires['area']\n",
    "fires['RH'] = fires['RH'].astype(float)\n",
    "X = fires.drop(['area'], axis = 1)\n",
    "\n",
    "int_to_cat_cols = (X.dtypes == int)\n",
    "cat_cols = (X.dtypes == object)\n",
    "num_cols = (X.dtypes == float)\n",
    "\n",
    "cat_pipe = Pipeline([\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "num_pipe = Pipeline([\n",
    "    ('scaler', StandardScaler())\n",
    "])\n",
    "\n",
    "preprocessing = ColumnTransformer([\n",
    "    ('categorical', cat_pipe, cat_cols),\n",
    "    ('categorical2', cat_pipe, int_to_cat_cols),\n",
    "    ('continuous', num_pipe, num_cols)\n",
    "])\n",
    "X_train, X_test, y_train, y_test = train_test_split(X,y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([\n",
    "    ('preprocesssing', preprocessing),\n",
    "    ('model', LinearRegression())\n",
    "])\n",
    "\n",
    "pipe.fit(X_train.values, y_train.values)\n",
    "\n",
    "y_pred = pipe.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([ 2.,  1.,  6., 16., 27., 19., 26., 22.,  8.,  3.]),\n",
       " array([-41.50146685, -31.65287387, -21.80428089, -11.95568791,\n",
       "         -2.10709493,   7.74149805,  17.59009103,  27.43868401,\n",
       "         37.28727699,  47.13586997,  56.98446295]),\n",
       " <a list of 10 Patch objects>)"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(31.842144585294985, 1013.9221717908307)"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "mse = mean_squared_error(y_test, y_pred)\n",
    "rmse, mse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Metrics scores aren't too bad, but we are predicting negative fire areas. That doesn't make any sense!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Resample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because the large fires are what we are intersted in, but there are so few of them, I will upsample the large fires and down sample the no fires. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Target engineering\n",
    "\n",
    "fires['fire'] = fires['area'] > 0\n",
    "fires['fire'] = fires['fire'].astype(int)\n",
    "fires['large'] = fires['area'] >np.std(fires['area'])  # I determined large fires to be larger than one standard deviation \n",
    "fires['large'] = fires['large'].astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.utils import resample\n",
    "# upsample the large fires\n",
    "\n",
    "df_majority = fires[(fires.large==0) & (fires.fire==1)]\n",
    "df_minority = fires[fires.large==1]\n",
    "\n",
    "df_minority_upsampled = resample(df_minority, \n",
    "                           replace=True,                     # sample with replacement\n",
    "                           n_samples=100,                    # make 100 large fires (19 before)\n",
    "                           random_state=123)                 # reproducible results\n",
    " \n",
    "# Combine majority class with upsampled minority class\n",
    "df_upsampled = pd.concat([df_majority, df_minority_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "# downsample majority class - no fires\n",
    "df_majority = fires[fires.fire==0]\n",
    "df_minority = fires[fires.fire==1]\n",
    " \n",
    "# Downsample majority class\n",
    "df_majority_downsampled = resample(df_majority, \n",
    "                                 replace=False,         # sample without replacement\n",
    "                                 n_samples=100,         # make no fires same amount as large fires\n",
    "                                 random_state=123)      # reproducible results\n",
    " \n",
    "# Combine minority class with downsampled majority class\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_resampled = pd.concat([df_majority_downsampled, df_upsampled])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(100, 100)"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_resampled['large'].sum(), len(df_resampled)-df_resampled['fire'].sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are now equal amount of large fires and no fires"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_resampled.drop(['area', 'fire', 'large'], axis =1)\n",
    "y = df_resampled['area']\n",
    "int_to_cat_cols = (X.dtypes == int)\n",
    "cat_cols = (X.dtypes == object)\n",
    "num_cols = (X.dtypes == float)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit scikit-learn model\n",
    "----"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Because we do no want negative values, a linear model is not appropraite. A tree based approach will correctly deal with this. \n",
    "Using a tree approach does not require standardizing the numeric variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_pipe = Pipeline([\n",
    "    ('ohe', OneHotEncoder(handle_unknown='ignore'))\n",
    "])\n",
    "\n",
    "preprocessing = ColumnTransformer([\n",
    "    ('categorical', cat_pipe, cat_cols),\n",
    "    ('categorical2', cat_pipe, int_to_cat_cols)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [],
   "source": [
    "# spilt into train, validation, and test\n",
    "\n",
    "y = df_resampled['area']\n",
    "X = df_resampled.drop(['area','fire','large'], axis =1)\n",
    "X_train, X_valid, y_train, y_valid = train_test_split(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(85, 253, 113)"
      ]
     },
     "execution_count": 97,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(y_test), len(y_train), len(y_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DecisionTreeRegressor     - mean squared error: 13236.577484477777\n",
      "DecisionTreeRegressor     - root mean squared error: 115.05032587732109\n",
      "\n",
      "AdaBoostRegressor         - mean squared error: 12080.471898809335\n",
      "AdaBoostRegressor         - root mean squared error: 109.9112000608188\n",
      "\n",
      "ExtraTreeRegressor        - mean squared error: 13299.838019020259\n",
      "ExtraTreeRegressor        - root mean squared error: 115.32492366795765\n",
      "\n",
      "RandomForestRegressor     - mean squared error: 11609.79463875339\n",
      "RandomForestRegressor     - root mean squared error: 107.74875701720828\n",
      "\n",
      "GradientBoostingRegressor - mean squared error: 12987.410590560534\n",
      "GradientBoostingRegressor - root mean squared error: 113.96232092477116\n",
      "\n"
     ]
    }
   ],
   "source": [
    "algorithms = [DecisionTreeRegressor(),\n",
    "              AdaBoostRegressor(),\n",
    "              ExtraTreeRegressor(), \n",
    "              RandomForestRegressor(),\n",
    "              GradientBoostingRegressor()]\n",
    "\n",
    "for algo in algorithms:\n",
    "    pipe = Pipeline([('preprocessing', preprocessing), \n",
    "                     ('model',         algo)])\n",
    "\n",
    "    pipe.fit(X_train, y_train)\n",
    "    y_pred = pipe.predict(X_test)\n",
    "    \n",
    "    mse = mean_squared_error(y_test, y_pred)\n",
    "    rmse = np.sqrt(mean_squared_error(y_test, y_pred))\n",
    "    print(f\"{algo.__class__.__name__:<25} - mean squared error: {mse}\")\n",
    "    print(f\"{algo.__class__.__name__:<25} - root mean squared error: {rmse}\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "RMSE penalizes outliers the most, and because we want to best predict the large fires we want to lowest RMSE score. \n",
    "The results are inconsistent so I will try a hyperparameter tune a few of these models to see which can best predict fire area."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Ada Boost Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    " 'learning_rate': [0.1, 0.5, 1.0, 2.0],\n",
    " 'loss': ['linear', 'square', 'exponential'],\n",
    " 'n_estimators': [10, 50, 100, 1000]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n"
     ]
    }
   ],
   "source": [
    "ada_cv = RandomizedSearchCV(estimator=AdaBoostRegressor(), \n",
    "                              param_distributions=hyperparameters, \n",
    "                              n_iter=10, \n",
    "                              cv=5, \n",
    "                              verbose=1,\n",
    "                              random_state=43)\n",
    "\n",
    "pipe_ada_cv = Pipeline([\n",
    "        ('preprocessing', preprocessing), \n",
    "        ('lr', ada_cv)])\n",
    "\n",
    "pipe_ada_cv.fit(X_train.values, y_train.values)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = ada_cv.best_estimator_.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_ada = Pipeline([('preprocessing', preprocessing), \n",
    "                     ('model',     AdaBoostRegressor(**hyperparams))])\n",
    "\n",
    "pipe_ada.fit(X_train, y_train)\n",
    "y_pred = pipe_ada.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = pipe_ada.score(X_test.values, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_ada = {'rmse':rmse, 'r2':r2 }"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gradient Boosting Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    " 'alpha': [0.1, 0.5, 0.9],\n",
    " 'criterion': ['friedman_mse', 'mse'],\n",
    " 'learning_rate': [0.01,0.1, 0.5, 1],\n",
    " 'loss': ['ls', 'lad', 'huber', 'quantile'],\n",
    " 'max_depth': [3, 5, 10],\n",
    " 'max_features': [None, 5, 10],\n",
    " 'min_samples_leaf': [1, 2, 5, 10],\n",
    " 'n_estimators': [10, 50, 100, 1000],\n",
    " 'warm_start': [False, True]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n"
     ]
    }
   ],
   "source": [
    "gb_cv = RandomizedSearchCV(estimator=GradientBoostingRegressor(), \n",
    "                              param_distributions=hyperparameters, \n",
    "                              n_iter=10, \n",
    "                              cv=5, \n",
    "                              verbose=1,\n",
    "                              random_state=43)\n",
    "\n",
    "pipe_gb_cv = Pipeline([\n",
    "        ('preprocessing', preprocessing), \n",
    "        ('model', gb_cv)])\n",
    "\n",
    "pipe_gb_cv.fit(X_train.values, y_train.values)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = gb_cv.best_estimator_.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pipe_gb = Pipeline([\n",
    "    ('preprocessing', preprocessing),\n",
    "    ('m', GradientBoostingRegressor(**hyperparams))\n",
    "])\n",
    "pipe_gb.fit(X_train.values, y_train.values)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_gb.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = pipe_gb.score(X_test.values, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_gb = {'rmse':rmse, 'r2':r2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Decision Tree Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {'ccp_alpha': [0.0, 0.1, 0.5],\n",
    " 'criterion': ['mse', 'friedman_mse', 'mae', 'poisson'],\n",
    " 'max_depth': [None, 5, 10, 50, 100],\n",
    " 'max_features': [None, 5, 10],\n",
    " 'max_leaf_nodes': [None, 10, 50, 100, 1000],\n",
    " 'min_samples_leaf': [1, 2, 5, 10],\n",
    " 'splitter': ['best', 'random']}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dt_cv = RandomizedSearchCV(estimator=DecisionTreeRegressor(), \n",
    "                              param_distributions=hyperparameters, \n",
    "                              n_iter=10, \n",
    "                              cv=5, \n",
    "                              verbose=1,\n",
    "                              random_state=43)\n",
    "\n",
    "pipe_dt_cv = Pipeline([\n",
    "        ('preprocessing', preprocessing), \n",
    "        ('lr', dt_cv)])\n",
    "\n",
    "pipe_dt_cv.fit(X_train.values, y_train.values)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = dt_cv.best_estimator_.get_params()\n",
    "hyperparams['random_state'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pipe_dt = Pipeline([\n",
    "    ('preprocessing', preprocessing),\n",
    "    ('m', DecisionTreeRegressor(**hyperparams))\n",
    "])\n",
    "pipe_dt.fit(X_train.values, y_train.values)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_dt.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = pipe_dt.score(X_test.values, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_dt = {'rmse':rmse, 'r2':r2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Random Forest Regressor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparameters = {\n",
    "     'bootstrap': [True, False],\n",
    "     'criterion': ['mse', 'mae'],\n",
    "     'max_depth': [1, 10, 50, 100],\n",
    "     'max_features': ['auto', 'sqrt', 'log2'],\n",
    "     'max_leaf_nodes': [10, 100, 1000],\n",
    "     'max_samples': [None],\n",
    "     'min_samples_leaf': [1, 10, 20],\n",
    "     'n_estimators': [10, 100, 1000],\n",
    "     'oob_score': [False],\n",
    "     'warm_start': [False, True]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 10 candidates, totalling 50 fits\n",
      "\n"
     ]
    }
   ],
   "source": [
    "rfr_cv = RandomizedSearchCV(estimator=RandomForestRegressor(), \n",
    "                              param_distributions=hyperparameters, \n",
    "                              n_iter=10, \n",
    "                              cv=5, \n",
    "                              verbose=1, \n",
    "                              random_state=43)\n",
    "\n",
    "pipe_rf_cv = Pipeline([('preprocessing',preprocessing),\n",
    "                ('rf', rfr_cv)])\n",
    "\n",
    "pipe_rf_cv.fit(X_train, y_train)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [],
   "source": [
    "hyperparams = rfr_cv.best_estimator_.get_params()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe_rf = Pipeline([\n",
    "    ('preprocessing', preprocessing),\n",
    "    ('m', RandomForestRegressor(**hyperparams))\n",
    "])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "pipe_rf.fit(X_train.values, y_train.values)\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_rf.predict(X_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [],
   "source": [
    "r2 = pipe_rf.score(X_test.values, y_test.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_rf = {'rmse':rmse, 'r2':r2}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Final Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "({'rmse': 141.25877644600448, 'r2': 0.06873977112851537},\n",
       " {'rmse': 116.2924354245241, 'r2': 0.3688347104970652},\n",
       " {'rmse': 110.36489805343362, 'r2': 0.4315371231152826},\n",
       " {'rmse': 115.4469326875538, 'r2': 0.3779791062215353})"
      ]
     },
     "execution_count": 131,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "scores_ada, scores_gb, scores_rf, scores_dt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "scores_ada['model']='Ada Boost Regressor'\n",
    "scores_gb['model']='Gradient Boosting'\n",
    "scores_rf['model']='Random Forest'\n",
    "scores_dt['model']='Decision Tree'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "metadata": {},
   "outputs": [],
   "source": [
    "models = pd.DataFrame.from_dict([scores_ada, scores_gb, scores_rf, scores_dt])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rmse</th>\n",
       "      <th>r2</th>\n",
       "      <th>model</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>141.258776</td>\n",
       "      <td>0.068740</td>\n",
       "      <td>Ada Boost Regressor</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>116.292435</td>\n",
       "      <td>0.368835</td>\n",
       "      <td>Gradient Boosting</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>110.364898</td>\n",
       "      <td>0.431537</td>\n",
       "      <td>Random Forest</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>115.446933</td>\n",
       "      <td>0.377979</td>\n",
       "      <td>Decision Tree</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         rmse        r2                model\n",
       "0  141.258776  0.068740  Ada Boost Regressor\n",
       "1  116.292435  0.368835    Gradient Boosting\n",
       "2  110.364898  0.431537        Random Forest\n",
       "3  115.446933  0.377979        Decision Tree"
      ]
     },
     "execution_count": 134,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.plot(models.model, models.rmse)\n",
    "plt.title('RMSE')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Random forest has the lowest RMSE and the highest R^2"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I decided to go with the Random Forest Regressor because of the metrics, and I would also expect to do well predicting this kind of data. With these outliers it is easy to overfit or not capture then accurately but a RF does a good job at this"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_rf.predict(X_valid.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(111.72220177386555, 0.29918763820436267)"
      ]
     },
     "execution_count": 137,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rmse = np.sqrt(mean_squared_error(y_valid, y_pred))\n",
    "r2 = pipe_rf.score(X_valid.values, y_valid.values)\n",
    "rmse, r2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "r = permutation_importance(pipe_rf, X_test.values, y_test.values,\n",
    "                            n_repeats=30,\n",
    "                            random_state=0)\n",
    "\n",
    "importances = list(zip(X_train.columns, r.importances_mean))\n",
    "importances = sorted(importances, key=lambda x: x[1])\n",
    "\n",
    "plt.barh(*zip(*importances))\n",
    "plt.xlabel('Feature Importance')\n",
    "plt.ylabel('Features')\n",
    "plt.title('Permutation Feature Importance')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Features importance is a very big take away from this model. This tells us which of the features was most predictive of a fire. As shown above, the day of the week, the month, and location are the bigget indicators of a fire. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(y_valid)\n",
    "plt.hist(y_pred)\n",
    "\n",
    "plt.xlabel('Burn area (hectares)')\n",
    "plt.ylabel('Number of fires')\n",
    "plt.title('Predicted Area')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Test model of original, not upsampled data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = fires['area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = fires.drop(['area', 'fire', 'large'], axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = pipe_rf.predict(X.values)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mae = mean_absolute_error(y, y_pred)\n",
    "rmse = np.sqrt(mean_squared_error(y, y_pred))\n",
    "mae, rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(fires['area'])\n",
    "plt.hist(y_pred)\n",
    "plt.xlabel('Burn area (hectares)')\n",
    "plt.ylabel('Number of fires')\n",
    "plt.title('Original Sample Data (orange = predicted)')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I was suspicous the model only worked well on the upsampled data. So I tried to predict the original data set and found it did a very good job at predicting burned area, including the large fires"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Upsampling turned out to be very effective method to help predict the large fires. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are obvious reason why this model is important. Uncontrolled forest fires can cause a lot of damage and because of human caused climate change, forest fires have become more frequent and larger (this only references my own personal knowledge, especially being in California in 2020). The features importances of this model can tell us a lot about what indicators might point to a fire the most. Out best model, the random forest, indicate that day, month, and location are the biggest predictors. A continuation of this project would be to find out which month and days, and which locations are the most predictive. Knowing these could help fire fighter be more prepared, and give warning to recreational users of the park to be extra safe when dealing with fire."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
